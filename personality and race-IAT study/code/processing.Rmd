---
title: "Examining the relationship between the big-5 personality facets and implicit racial attitudes"
subtitle: "Data processing"
author: "Andreas Szukics"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    # code_folding: hide
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
    css: styles.css  # CSS file for costumized html
---

```{r, include=FALSE}

knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

```


# Libraries

```{r}

library(tidyverse)
library(knitr)
library(kableExtra)
library(janitor)
library(stringr)
library(openxlsx)

```


# Loading data

```{r}

# Demographics
data_dem_raw <- read_csv("../data/raw/data_raw_demographics.csv") |>
  clean_names()


# BFI
data_bfi_raw <- read_csv("../data/raw/data_raw_bfi.csv") |>
  clean_names()


# IAT
data_iat_raw <- read_csv("../data/raw/data_raw_iat.csv") |>
  clean_names()


# print(data_dem_raw)
# print(data_bfi_raw)
# print(data_iat_raw)

```


# Demographics

```{r, results='asis'}
# Checking variables' class
# map(data_dem_raw, class)


# Pivoting the data frame and separating gender and age
data_age_gen <- data_dem_raw |>
  pivot_wider(names_from  = variable,
              values_from = response) |> 
  rename(subject = unique_id,
          gender = sex) |>
  mutate(gender = as.character(gender), # case_when does not work otherwise (classed as a list after bevor because of NAs)
         age    = as.character(age))


# Value check
table(data_age_gen$gender, useNA = "ifany") |>  #checking the values in gender to use below
  kable()  |>
  kable_classic(full_width = FALSE)


# Mutating values (NAs or Null)
data_age_gen <- data_age_gen         |>
  mutate(gender  = as.character(gender), # case_when does not work otherwise (classed as a list after bivor because of NAs)
         age     = as.character(age),    # case_when does not work otherwise (classed as a list after bivor because of NAs)
         gender  = tolower(gender),
         gender  = stringr::str_remove_all(gender, regex("\\W+")),
         gender  = case_when(gender == "f" ~ "female",  # checking for NAs and renaming them and changing f/m to female/male
                             gender == "m" ~ "male",   
                             TRUE ~ "other/missing/error"),
         age     = case_when(str_detect(age, "^[0-9]+$") ~ age,
                             TRUE ~ "other/missing/error"),
         subject = case_when(is.na(subject) ~ "other/missing/error",
                             TRUE ~ as.character(subject))) # there is one missing subject nr
         

# checking the class for age and gender
# map(data_age_gen, class)

```


# Data processing

## BFI:

### Reverse scaling

```{r}

# Reverse scaling subscale items
data_bfi_rs <- data_bfi_raw |> 
  rename(subject = unique_id) |> 
  #selecting the items to be reverse scaled
  mutate_at(vars(bfi_a1, bfi_a3, bfi_a6, bfi_a8,
                 bfi_c2, bfi_c4, bfi_c5, bfi_c9,
                 bfi_e2, bfi_e5, bfi_e7,
                 bfi_n2, bfi_n5, bfi_n7,
                 bfi_o7, bfi_o9), 
            ~ ifelse(!is.na(.), 7 - ., NA)) # subtracting 7 with the item. NAs are ignored
              
```


#### Sanity check for reversal (correlations)

```{r}

# List of subscales
subscales <- c("a", "c", "e", "n", "o")
num_items <- c(9, 9, 8, 8, 10)


# Empty list to store correlation matrices
cor_matrices <- list()

# Nested loop to compute correlations for each subscale
for (i in seq_along(subscales)) {
    # Generate column names for the current subscale
    selected_columns <- paste0("bfi_", subscales[i], 1:num_items[i])
  
    # Create a subset of data for the current subscale
    dat_subscale <- data_bfi_rs[, selected_columns, drop = FALSE]
  
    # Compute correlation matrix
    cor_matrix <- cor(dat_subscale, use = "pairwise.complete.obs")
  
    # Store the correlation matrix in the list
    cor_matrices[[subscales[i]]] <- cor_matrix
}

# Print Corr. Matrix
# print(cor_matrices)

```


```{r, results='asis'}

# Table for the correlations
for (i in seq_along(cor_matrices)) {
    cat("\nCorrelation Matrix for Subscale:", names(cor_matrices)[i], "\n")
    print(
        knitr::kable(cor_matrices[[i]]) %>%
        kable_classic(full_width = FALSE)
    )
}

```


### Completeness check

```{r}
# List of subscales
subscales <- c("a", "c", "e", "n", "o")
num_items <- c(9, 9, 8, 8, 10)


# Empty list to store completeness information
completeness_info <- list()

for (i in seq_along(subscales)) {
    selected_columns <- paste0("bfi_", subscales[i], 1:num_items[i])
    
    # Select columns for the current subscale using standard subsetting
    dat_subscale <- data_bfi_rs[, c("subject", selected_columns), drop = FALSE]
    
    
    # Check if subscale has been started or completed
    subscale_started <- rowSums(!is.na(dat_subscale[, -1])) > 0
    subscale_completed <- rowSums(!is.na(dat_subscale[, -1])) == num_items[i]
    subscale_started_but_not_completed <- subscale_started & !subscale_completed
    
  
    # Store completeness information in the list
    completeness_info[[subscales[i]]] <- data.frame(subject = dat_subscale$subject, 
                                                    started = subscale_started,
                                                    incomplete = subscale_started_but_not_completed)
    

    # Additional check for range of responses within 1 to 6
    included_subjects <- dat_subscale$subject[subscale_completed]

    for (subject in included_subjects) {
        # Extract the responses for this subject and subscale
        subject_responses <- dat_subscale[dat_subscale$subject == subject, -1]
        # Check if any response is outside the 1-6 range
        if (any(subject_responses < 1 | subject_responses > 6, na.rm = TRUE)) {
            # Mark as incomplete in the completeness_info list
            completeness_info[[subscales[i]]]$incomplete[completeness_info[[subscales[i]]]$subject == subject] <- TRUE
        }
    }
}

# Combine completeness information for all subscales
completeness_combined <- Reduce(function(x, y) merge(x, y, by = "subject", all = TRUE), completeness_info)


# Determine if at least 2 subscales are complete and no subscales started but not completed
completeness_combined$at_least_2_complete <- rowSums(completeness_combined[, -1], na.rm = TRUE) >= 2
no_started_incomplete_subscale <- rowSums(completeness_combined[, grep("incomplete", names(completeness_combined))], na.rm = TRUE) == 0


# Create the 'include_exclude' column
completeness_combined$include_exclude_bfi <- ifelse(completeness_combined$at_least_2_complete & no_started_incomplete_subscale, "include", "exclude")


# Merge with the original BFI data
data_bfi_check <- merge(data_bfi_rs, completeness_combined[, c("subject", "include_exclude_bfi")], by = "subject", all.x = TRUE) 

```


### Sanity check for inclusion/exclusion

```{r}

# List of subscales
subscales <- c("a", "c", "e", "n", "o")
num_items <- c(9, 9, 8, 8, 10)


# Initialize lists to store subjects
subjects_outside_range <- list()
subjects_with_NAs <- list()

for (i in seq_along(subscales)) {
  selected_columns <- paste0("bfi_", subscales[i], 1:num_items[i])
  
  
  # Select columns for the current subscale
  dat_subscale <- data_bfi_rs[, c("subject", selected_columns), drop = FALSE]
  

  # Check if subscale has been started
  subscale_started <- rowSums(!is.na(dat_subscale[, -1])) > 0
  started_subjects <- dat_subscale$subject[subscale_started]
  

  # Initialize vectors to store subjects for this subscale
  subjects_outside_range[[subscales[i]]] <- c()
  subjects_with_NAs[[subscales[i]]] <- c()
  
  for (subject in started_subjects) {
   
    subject_responses <- dat_subscale[dat_subscale$subject == subject, -1]  # Extract responses for this subject and subscale

    
    if (any(subject_responses < 1 | subject_responses > 6, na.rm = TRUE)) { # Check for values outside the 1-6 range
      subjects_outside_range[[subscales[i]]] <- c(subjects_outside_range[[subscales[i]]], subject)
    }

    
    if (any(is.na(subject_responses))) { # Check for NA values
      subjects_with_NAs[[subscales[i]]] <- c(subjects_with_NAs[[subscales[i]]], subject)
    }
  }
}


# Combine lists into a named list for easy reference
final_list <- list(subjects_outside_range = subjects_outside_range,
                   subjects_with_NAs = subjects_with_NAs)


# print the final list
print(final_list)

```


### Mean scoring the bfi

```{r}

# List of subscales
subscales <- c("a", "c", "e", "n", "o")


# Function to calculate mean for a given subscale
calculate_mean_subscale <- function(data, subscale) {
  data |>
    select(starts_with(paste0("bfi_", subscale))) |>
    rowMeans(na.rm = TRUE)
}


# Calculate mean scores for each subscale for each subject
mean_score_bfi <- data_bfi_check |>
  group_by(subject) |>
  summarize(mean_a = calculate_mean_subscale(cur_data(), "a"),
            mean_c = calculate_mean_subscale(cur_data(), "c"),
            mean_e = calculate_mean_subscale(cur_data(), "e"),
            mean_n = calculate_mean_subscale(cur_data(), "n"),
            mean_o = calculate_mean_subscale(cur_data(), "o"),
            .groups = "drop")


# adding the include_exclude_bfi column to the mean_score_bfi dataframe
mean_score_bfi <- mean_score_bfi |>
  left_join(data_bfi_check |> select(subject, include_exclude_bfi), by = "subject")


# print the mean scores per subject
# print(mean_score_bfi)

```


### Min max check for bfi means

```{r}

# Filter for included subjects
included_subjects <- data_bfi_check |>
  filter(include_exclude_bfi == "include")


# Function to find min and max values for each subscale
find_min_max <- function(data, subscale) {
  min_max <- data |>
    select(starts_with(subscale)) %>% 
    summarise(min = min(., na.rm = TRUE), max = max(., na.rm = TRUE))
  return(min_max)
}


# Find min and max for each subscale based on included subjects
min_max_a <- find_min_max(included_subjects, "bfi_a")
min_max_c <- find_min_max(included_subjects, "bfi_c")
min_max_e <- find_min_max(included_subjects, "bfi_e")
min_max_n <- find_min_max(included_subjects, "bfi_n")
min_max_o <- find_min_max(included_subjects, "bfi_o")


# Function to check if mean is within the range
check_mean_range <- function(mean_score, min, max) {ifelse(mean_score >= min & mean_score <= max, "Valid", "Invalid")}


# Checking the range check of each mean subscale score for all subjects 
mean_score_bfi <- mean_score_bfi |> 
  mutate(check_mean_a = check_mean_range(mean_a, min_max_a$min, min_max_a$max),
         check_mean_c = check_mean_range(mean_c, min_max_c$min, min_max_c$max),
         check_mean_e = check_mean_range(mean_e, min_max_e$min, min_max_e$max),
         check_mean_n = check_mean_range(mean_n, min_max_n$min, min_max_n$max),
         check_mean_o = check_mean_range(mean_o, min_max_o$min, min_max_o$max)) |> 
  rename(include_exclude_bfi_mean = include_exclude_bfi)


# print the updated dataframe with range checks
 # print(mean_score_bfi)

```


## IAT

### preparing for mean score

```{r}

# Initial processing and calculations
data_iat_var <- data_iat_raw |>
  slice(-1) |>                                                         # Removing the first row for column names
  setNames(as.character(unlist(data_iat_raw[1, ]))) |>                 # Setting first row as variables
  clean_names() |>                                                     # Adjusting the variable names to snake case
  rename(subject  = unique_id,
         rt       = trial_reaction_time_in_ms,
         accuracy = trial_accuracy,
         block    = block_number) |>
  filter(!block %in% c(1, 2, 5)) |>                                    # Removing blocks 1, 2, and 5
  group_by(subject) |> 
  mutate(trial_count = n()) |>                                         # Counting the number of trials per subject in each group
  ungroup() |>                                                         # Ungrouping to apply the next operations to the entire dataset
  mutate(include_exclude_iat = ifelse(trial_count == 120, "include", "exclude"),
         rt                  = as.numeric(rt)) |>                      # Marking subjects as include or exclude
  mutate(latency_prob  = if_else(rt < 300, TRUE, FALSE),
         accuracy_prob = if_else(accuracy == "correct", TRUE, FALSE))  # Marking subjects as include or exclude
  

# Calculate proportion of fast trials for each subject
proportion_rt_acc <- data_iat_var |>
  group_by(subject) |>
  summarize(proportion_fast_trials = mean(latency_prob, na.rm = TRUE),
            proportion_accuracy    = mean(accuracy_prob, na.rm = TRUE)) |>
  mutate(exclude_performance = ifelse(proportion_fast_trials > 0.10| proportion_accuracy < 0.75, "exclude", "include")) #excluding too fast and or inaccurate trials

# Joining the proportion back to the original data and updating include_exclude
data_iat_var <- data_iat_var |>
  left_join(proportion_rt_acc, by = "subject") |>
  mutate(include_exclude_iat = ifelse(exclude_performance == "exclude", "exclude", include_exclude_iat)) |>
  select(-exclude_performance)

# print the resulting dataframe
# print(data_iat_var)

```


### check for trial count

```{r}

#checking trial count by subject
data_iat_var |> 
  group_by(subject) |> 
  summarize(trial_count = n())


```


### Mean scoring IAT

```{r}

# Calculate mean scores first
mean_score_iat <- data_iat_var |> 
  mutate(
    rt_block_3_6 = ifelse(block %in% c(3, 6), rt, NA),  # Combining block 3 + 6 and 4 + 7
    rt_block_4_7 = ifelse(block %in% c(4, 7), rt, NA)
  )  |> 
  group_by(subject) |>
  summarize(
    mean1 = mean(rt_block_3_6, na.rm = TRUE),           # Mean for blocks 3 + 6
    mean2 = mean(rt_block_4_7, na.rm = TRUE),           # Mean for blocks 4 + 7
    SD    = sd(rt, na.rm = TRUE),                       # Standard deviation of all rt values
    .groups = "drop"
  ) |> 
  mutate(
    D       = (mean2 - mean1) / SD,
    D_check = ifelse(D > -2 & D < 2, "within range", "outside range")
  )


# adding the include_exclude_iat column
mean_score_iat <- mean_score_iat |> 
  left_join(data_iat_var %>% select(subject, include_exclude_iat) %>% distinct(), by = "subject")


# print the updated dataframe
# print(mean_score_iat)


```


# Combining demographics, BFI and IAT

```{r}

# Checking variable subject class
# map(data_age_gen, class)
# map(data_bfi_check, class)
# map(mean_score_bfi, class)
# map(mean_score_iat, class)


#changing subject class to character because the join wont work
data_bfi_check <- data_bfi_check|> 
  mutate(subject = as.character(subject))

mean_score_bfi <- mean_score_bfi|> 
  mutate(subject = as.character(subject))


# combine all dfs created in the previous chunks
data_processed_temp <- data_age_gen |> 
  inner_join(data_bfi_check, by = "subject") |> #using inner_join because data_age_gen has many more entries 
  inner_join(mean_score_bfi, by = "subject") |> 
  inner_join(mean_score_iat, by = "subject") 


# Checking for duplicate subjects
data_processed_duplicates <- data_processed_temp |>
  count(subject) |>
  mutate(exclude_duplicate_data = if_else(n > 1, "exclude", "include")) |>
  select(-n)

# join in the duplicates df
data_processed_before_exclusions <- data_processed_temp |>
  full_join(data_processed_duplicates, by = "subject")

```


# Define master exclusions

```{r}

# master exclude_participant variable
data_processed <- data_processed_before_exclusions |>
  mutate(exclude_participant = case_when(tolower(age)             == "other/missing/error" ~ "exclude",
                                         tolower(gender)          == "other/missing/error" ~ "exclude",
                                         is.na(mean1)              ~ "exclude",
                                         is.na(mean2)              ~ "exclude",
                                         is.na(D)                  ~ "exclude",
                                         is.na(mean2)              ~ "exclude",
                                         is.na(age)                ~ "exclude", 
                                         is.na(gender)             ~ "exclude",
                                         # Checking if any of the variables below say exclude. if they do the subject is to be excluded
                                         include_exclude_bfi      == "exclude" ~ "exclude", 
                                         include_exclude_bfi_mean == "exclude" ~ "exclude",
                                         include_exclude_iat      == "exclude" ~ "exclude",
                                         exclude_duplicate_data   == "exclude" ~ "exclude", 
                                         TRUE ~ "include"))

```

# Write to disk

```{r}

# in case this dir doesn't exist, create it
dir.create("../data/processed/")

# save data to disk in that dir
write_csv(data_processed, "../data/processed/data_processed.csv")

```

# Create codebook template for the processed data

```{r}

if(!file.exists("../communications/data_processed_codebook.xlsx")){
  # convert the column names to a df
  codebook_template <- data.frame(variable = colnames(data_processed)) |>
    mutate(explanation = NA)
  # write to disk as an excel file
  write.xlsx(codebook_template, file = "../communications/data_processed_codebook.xlsx")
}

```


# Session info

```{r}

sessionInfo()

```





